{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63364a85",
   "metadata": {},
   "source": [
    "## Step 0 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f97017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: feel free to utilize libraries that you find helpful\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb61b440",
   "metadata": {},
   "source": [
    "## Step 1 — Reproducibility + device\n",
    "\n",
    "- **Reproducibility:** We fix random seeds so dataset shuffling, weight initialization, and dropout are as repeatable as possible across runs. This makes results comparable and debugging meaningful.\n",
    "\n",
    "- **Determinism controls:** Setting `torch.backends.cudnn.deterministic=True` and `benchmark=False` reduces non-deterministic GPU behavior (at a potential speed cost), so you don’t “win or lose” accuracy due to hidden algorithm choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b33621",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED: int = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405aa2c",
   "metadata": {},
   "source": [
    "## Step 2 — Load Fashion-MNIST dataset\n",
    "\n",
    "> Remember that in seminar we did MNIST dataset that was only for digit classification.\n",
    "\n",
    "Now we're working with a standardized image classification benchmark: 28×28 grayscale **clothing** photos, 10 classes, with an official 60k/10k train/test split.\n",
    "\n",
    "We'll download it without specific options to later do normalization&shuffling ourselves in order to understand how it's done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES: list[str] = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"fashion_mnist\")  # cached under ~/.cache/huggingface/datasets by default\n",
    "\n",
    "# Make columns come out as NumPy arrays where possible.\n",
    "train_split = ds[\"train\"].with_format(\"numpy\")\n",
    "test_split = ds[\"test\"].with_format(\"numpy\")\n",
    "\n",
    "\n",
    "def _images_to_u8(images: object) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The 'image' column can come back either as:\n",
    "      - a single np.ndarray of shape [N, 28, 28], or\n",
    "      - a list-like of [28, 28] arrays.\n",
    "    Normalize it into a uint8 ndarray [N, 28, 28].\n",
    "    \"\"\"\n",
    "    if isinstance(images, np.ndarray):\n",
    "        arr = images\n",
    "    else:\n",
    "        arr = np.stack(images)  # works if it's list-like of 2D arrays\n",
    "    return arr.astype(np.uint8)\n",
    "\n",
    "\n",
    "train_images_u8 = _images_to_u8(train_split[\"image\"])\n",
    "train_labels_i64 = np.asarray(train_split[\"label\"], dtype=np.int64)\n",
    "\n",
    "test_images_u8 = _images_to_u8(test_split[\"image\"])\n",
    "test_labels_i64 = np.asarray(test_split[\"label\"], dtype=np.int64)\n",
    "\n",
    "assert train_images_u8.shape == (60_000, 28, 28)\n",
    "assert train_labels_i64.shape == (60_000,)\n",
    "assert test_images_u8.shape == (10_000, 28, 28)\n",
    "assert test_labels_i64.shape == (10_000,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f1c5b",
   "metadata": {},
   "source": [
    "## Step 3 — Data Visualization **[1 point]**\n",
    "\n",
    "***Task***:\n",
    "\n",
    "- Randomly select a small set of training examples.\n",
    "\n",
    "- Display them as a grid of grayscale images.\n",
    "\n",
    "- Put the class name (decoded from the numeric label) as the title for each image.\n",
    "\n",
    "- Verify visually that:\n",
    "  - the images look like clothing silhouettes (not noise/corrupted)\n",
    "  - labels match what you see (e.g., sneaker vs sandal)\n",
    "  - pixel orientation/contrast looks reasonable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a8336",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_n = 16\n",
    "idx = np.random.default_rng(SEED).choice(\n",
    "    len(train_images_u8), size=grid_n, replace=False\n",
    ")\n",
    "\n",
    "raise NotImplementedError # TODO: <your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55feb488",
   "metadata": {},
   "source": [
    "## Step 4 — Train/val split + normalization **[1 point]**\n",
    "\n",
    "***Task***:\n",
    "\n",
    "- Create a **train/validation split** from the **shuffled (by you!)** original training set (e.g., 90% train, 10% val).\n",
    "\n",
    "- Compute **normalization statistics (mean and std)** using **only the train split**.\n",
    "\n",
    "- Apply the same normalization to **train, val, and test** using the train-derived mean/std.\n",
    "\n",
    "- Add a channel dimension to get `[N, 1, 28, 28]`\n",
    "\n",
    "    > We add a channel dimension so each sample matches the standard image tensor convention **[C, H, W]** (and batches **[N, C, H, W]**).  \n",
    "    Even for grayscale, **C=1** is required so downstream layers and dataloaders can treat grayscale and RGB images uniformly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fraction: float = 0.10\n",
    "\n",
    "n_total = train_images_u8.shape[0]\n",
    "n_val = int(n_total * val_fraction)\n",
    "n_train = n_total - n_val\n",
    "\n",
    "raise NotImplementedError # TODO: <your code here>\n",
    "\n",
    "train_images = train_images_u8[train_idx]\n",
    "train_labels = train_labels_i64[train_idx]\n",
    "val_images = train_images_u8[val_idx]\n",
    "val_labels = train_labels_i64[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c26e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean =  # TODO: <your code here>\n",
    "std =   # TODO: <your code here>\n",
    "# NOTE: we need them later for denormalization also!\n",
    "\n",
    "print(f\"Normalization (computed on TRAIN split only): mean={mean:.6f}, std={std:.6f}\")\n",
    "\n",
    "\n",
    "def normalize_u8(images_u8: np.ndarray, mean: float, std: float) -> np.ndarray:\n",
    "    \"\"\"Convert uint8 images [N,28,28] -> float32 normalized [N,1,28,28].\"\"\"\n",
    "    raise NotImplementedError # TODO: <your code here>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57773803",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize_u8(train_images, mean, std)\n",
    "x_val = normalize_u8(val_images, mean, std)\n",
    "x_test = normalize_u8(test_images_u8, mean, std)\n",
    "\n",
    "y_train = train_labels.astype(np.int64)\n",
    "y_val = val_labels.astype(np.int64)\n",
    "y_test = test_labels_i64.astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031cb3cf",
   "metadata": {},
   "source": [
    "## Step 5 — Dataset + DataLoaders **[1 point]**\n",
    "\n",
    "***Task***:\n",
    "\n",
    "- Wrap `(x, y)` arrays into a custom `Dataset` that:\n",
    "  - validates shapes (`x: [N,C,H,W]`, `y: [N]`):\n",
    "    - validate `x` shape\n",
    "    - validate `y` shape\n",
    "    - validate that they length match\n",
    "\n",
    "  - wraps `(x, y)` into `torch.Tensor`\n",
    "\n",
    "  - returns one `(image_tensor, label_tensor)` per index\n",
    "\n",
    "- Create `DataLoader`s for train/val/test that:\n",
    "  - batch samples (set `batch_size`)\n",
    "\n",
    "  - shuffle _only_ the training loader\n",
    "\n",
    "  - enable `pin_memory` when using CUDA for faster host $\\to$ GPU transfers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbcef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTFromNumpy(Dataset[tuple[torch.Tensor, torch.Tensor]]):\n",
    "    def __init__(self, x: np.ndarray, y: np.ndarray):\n",
    "        raise NotImplementedError # TODO: <your code here>\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        raise NotImplementedError # TODO: <your code here>\n",
    "\n",
    "\n",
    "train_ds = FashionMNISTFromNumpy(x_train, y_train)\n",
    "val_ds = FashionMNISTFromNumpy(x_val, y_val)\n",
    "test_ds = FashionMNISTFromNumpy(x_test, y_test)\n",
    "\n",
    "batch_size: int = 256\n",
    "pin_memory: bool = torch.cuda.is_available()\n",
    "\n",
    "train_loader = DataLoader(...)  # TODO: <your code here>\n",
    "val_loader = DataLoader(...)    # TODO: <your code here>\n",
    "test_loader = DataLoader(...)   # TODO: <your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16712104",
   "metadata": {},
   "source": [
    "## Step 6 — Model + loss + optimizer **[1 point]**\n",
    "\n",
    "***Task:***\n",
    "\n",
    "- Create your classifier (start with some simple baseline) appropriate for 28×28 images:\n",
    "  - **linear (logistic regression)** on flattened pixels *<[good for baseline]>*\n",
    "\n",
    "  - **MLP(FFN)** on flattened pixels with `nn.Dropout` & `nn.BatchNorm` *<[our seminar choice]>*:\n",
    "    - here you can use `nn.Linear`, `nn.ReLU`, `nn.Dropout`, `nn.BatchNorm`, maybe try to use `nn.Sequential` for easier way of work\n",
    "\n",
    "  - **CNN** *<[if you soooo cool and bored with MLP and ready to learn something new yourself!]>*:\n",
    "    - here you can use `nn.Conv2d`, `nn.MaxPool2d`\n",
    "\n",
    "    - > NOTE: for using CNN you _won't_ get any additional points, so if you're new to DL, stick to MLP\n",
    "\n",
    "- Use `nn.CrossEntropyLoss` for 10-way classification (raw logits, no softmax in the model).\n",
    "\n",
    "- Use an optimizer that works well out of the box (maybe `Adam` will do the thing)\n",
    "\n",
    "- Start with reasonable hyperparameters:\n",
    "  - learning rate: remember of how we came up with learning rate value in seminar class using ideas of normalization of data and normalization _within_ our NN\n",
    "\n",
    "  - maybe try out **weight decay** (which is direct way of doing regularization, like LASSO or RIDGE in simple linear regression)\n",
    "\n",
    "- Move model (and later batches) to the selected device (`cpu`/`cuda`) using `.to(device)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_features: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        raise NotImplementedError # TODO: <your code here>\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        raise NotImplementedError # TODO: <your code here>\n",
    "\n",
    "\n",
    "model =     # TODO: <your code here>\n",
    "criterion = # TODO: <your code here>\n",
    "optimizer = # TODO: <your code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf40c6",
   "metadata": {},
   "source": [
    "## Step 7 — Metrics helpers **[1 point]**\n",
    "\n",
    "***Task:***\n",
    "\n",
    "- Implement a confusion-matrix accumulator that:\n",
    "  - converts logits to predicted labels (`argmax`)\n",
    "\n",
    "  - counts `(true, pred)` pairs into an `[K, K]` matrix\n",
    "\n",
    "  - can be summed across batches to cover the full split\n",
    "\n",
    "- Implement metric computation from the confusion matrix:\n",
    "  - compute per-class precision/recall/F1\n",
    "\n",
    "  - compute overall accuracy\n",
    "\n",
    "  - compute macro-F1 (mean over classes)\n",
    "\n",
    "Make these utilities `no_grad`-safe and numerically safe (avoid division by zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad56967",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def confusion_matrix_from_logits(\n",
    "    logits: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    n_classes: int,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Build a confusion matrix from model logits and integer targets.\n",
    "\n",
    "    Args:\n",
    "        logits: Tensor of shape [B, n_classes] containing unnormalized class scores.\n",
    "        targets: Tensor of shape [B] containing ground-truth class indices in [0, n_classes-1].\n",
    "        n_classes: Total number of classes.\n",
    "\n",
    "    Returns:\n",
    "        Confusion matrix - a tensor of shape [n_classes, n_classes] with dtype int64, where:\n",
    "          - rows correspond to true classes\n",
    "          - columns correspond to predicted classes\n",
    "        Entry cm[i, j] is the number of samples with true class i predicted as class j.\n",
    "\n",
    "    Notes:\n",
    "        Runs under no-grad (evaluation utility). Computation is performed on CPU for counting.\n",
    "    \"\"\"\n",
    "    preds = torch.argmax(logits, dim=1).view(-1).to(\"cpu\")\n",
    "    t = targets.view(-1).to(\"cpu\")\n",
    "\n",
    "    raise NotImplementedError # TODO: <your code here>\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def metrics_from_confusion_matrix(cm: torch.Tensor) -> dict[str, object]:\n",
    "    \"\"\"\n",
    "    Compute classification metrics from a confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        cm: Confusion matrix tensor of shape [n_classes, n_classes] with nonnegative counts,\n",
    "            where rows are true classes and columns are predicted classes.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "          - \"accuracy\": float, overall accuracy (sum(diagonal) / sum(all))\n",
    "          - \"macro_f1\": float, mean of per-class F1 scores (uniform class weighting)\n",
    "          - \"precision_per_class\": list[float], per-class precision\n",
    "          - \"recall_per_class\": list[float], per-class recall\n",
    "          - \"f1_per_class\": list[float], per-class F1\n",
    "          - \"support_per_class\": list[int], number of true samples per class (row sums)\n",
    "          - \"confusion_matrix\": list[list[int]], cm converted to nested Python lists\n",
    "\n",
    "    Notes:\n",
    "        Uses clamping / epsilon safeguards to avoid division-by-zero when a class has zero\n",
    "        support (no true samples) or zero predicted count (never predicted).\n",
    "    \"\"\"\n",
    "    cm_f = cm.float()\n",
    "    diag = torch.diag(cm_f)\n",
    "    support = cm_f.sum(dim=1).clamp_min(1.0)\n",
    "    pred_count = cm_f.sum(dim=0).clamp_min(1.0)\n",
    "\n",
    "    precision = (diag / pred_count).cpu().numpy()\n",
    "    recall =    # TODO: <your code here>\n",
    "    f1 =        # TODO: <your code here>\n",
    "    macro_f1 = float(np.mean(f1))\n",
    "\n",
    "    accuracy =  # TODO: <your code here>\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"precision_per_class\": precision.tolist(),\n",
    "        \"recall_per_class\": recall.tolist(),\n",
    "        \"f1_per_class\": f1.tolist(),\n",
    "        \"support_per_class\": cm.sum(dim=1).tolist(),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40c97d",
   "metadata": {},
   "source": [
    "## Step 8 — Train with per-epoch validation + live visualization **[2 points]**\n",
    "\n",
    "***Task:***\n",
    "\n",
    "- Run training for a fixed number of epochs.\n",
    "\n",
    "- For each epoch:\n",
    "  - **Training phase:** set `model.train()`, iterate over `train_loader`, do forward → loss → backward → optimizer step, accumulate average train loss and train accuracy.\n",
    "\n",
    "  - **Validation phase:** set `model.eval()` and `torch.no_grad()`, iterate over `val_loader`, compute average val loss and val accuracy.\n",
    "\n",
    "- Store per-epoch metrics in lists (loss/accuracy for train and val).\n",
    "\n",
    "- After each epoch:\n",
    "  - Update plots of:\n",
    "    - train vs val **loss**\n",
    "    - train vs val **accuracy**\n",
    "    using `clear_output(wait=True)` so the curves refresh in-place.\n",
    "\n",
    "  - Print a compact epoch summary line with the tracked metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd27896",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs: int = # TODO: <your code here>\n",
    "\n",
    "train_losses: list[float] = []\n",
    "val_losses: list[float] = []\n",
    "train_accs: list[float] = []\n",
    "val_accs: list[float] = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # ---- train\n",
    "    # TODO: <your code here>\n",
    "\n",
    "    # ---- validation\n",
    "    # TODO: <your code here>\n",
    "\n",
    "\n",
    "    # ---- live plots\n",
    "    # TODO: <your code here>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f328f9b0",
   "metadata": {},
   "source": [
    "## Step 9 — Test evaluation **[1 point]**\n",
    "\n",
    "***Task:***\n",
    "\n",
    "- Switch to evaluation mode: `model.eval()` and disable gradients with `with torch.no_grad(): ...`.\n",
    "\n",
    "- Iterate over `test_loader` once and compute:\n",
    "  - average **test loss**\n",
    "\n",
    "  - total **confusion matrix** accumulated across all batches\n",
    "\n",
    "- From the final confusion matrix, compute and report:\n",
    "  - overall **accuracy**\n",
    "\n",
    "  - **macro-F1**\n",
    "\n",
    "  - per-class **precision/recall/F1** and **support**\n",
    "\n",
    "- Print the confusion matrix (rows=true, cols=pred) for error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bef029",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(CLASS_NAMES)\n",
    "\n",
    "model.eval()\n",
    "cm = torch.zeros((n_classes, n_classes), dtype=torch.int64)\n",
    "test_loss_sum = 0.0\n",
    "test_n = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        # TODO: <your code here>\n",
    "\n",
    "        b = x.shape[0]\n",
    "        test_loss_sum += float(loss.item()) * b\n",
    "        test_n += b\n",
    "\n",
    "        cm += confusion_matrix_from_logits(logits, y, n_classes=n_classes)\n",
    "\n",
    "test_loss = test_loss_sum / max(1, test_n)\n",
    "m = metrics_from_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f078b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTest evaluation\")\n",
    "print(f\"  loss:     {test_loss:.6f}\")\n",
    "print(f\"  accuracy: {float(m['accuracy']):.6f}\")\n",
    "print(f\"  macro_f1: {float(m['macro_f1']):.6f}\")\n",
    "\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for k in range(n_classes):\n",
    "    p = float(m[\"precision_per_class\"][k])\n",
    "    r = float(m[\"recall_per_class\"][k])\n",
    "    f1 = float(m[\"f1_per_class\"][k])\n",
    "    sup = int(m[\"support_per_class\"][k])\n",
    "    print(\n",
    "        f\"  class {k:02d} ({CLASS_NAMES[k]:>11s}) | P={p:.4f} R={r:.4f} F1={f1:.4f} support={sup}\"\n",
    "    )\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(np.array(m[\"confusion_matrix\"], dtype=np.int64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b25bb",
   "metadata": {},
   "source": [
    "## Step 10 — Show example classifications **[1 point]**\n",
    "\n",
    "***Task:***\n",
    "\n",
    "- Randomly pick a small set of test indices (e.g., 12).\n",
    "\n",
    "- Build a batch from those samples and run a forward pass in `model.eval()` + `torch.no_grad()`.\n",
    "\n",
    "- Convert logits to:\n",
    "  - predicted class (`argmax`)\n",
    "\n",
    "  - confidence (max softmax probability)\n",
    "\n",
    "- Visualize the selected images in a grid:\n",
    "  - display the image in original pixel space (invert normalization for plotting)\n",
    "\n",
    "  - title each with **true label**, **predicted label**, and **confidence**\n",
    "\n",
    "  - color the title by correctness (correct vs incorrect) to spot patterns quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe409c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: <your code here>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_3_14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
